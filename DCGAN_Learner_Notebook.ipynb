{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cnX0atWNppA3"
   },
   "source": [
    "<h2 align=center>Generate Synthetic Images with DCGANs in Keras</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AY-qM-4swLUb"
   },
   "source": [
    "## Task 1: Project Overview and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bhqrEV6hkFC3",
    "outputId": "6b3ac373-d05e-4996-f6b6-6df0268081c7"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import plot_utils\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from IPython import display\n",
    "print('Tensorflow version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bRT9FVAdwUDP"
   },
   "source": [
    "## Task 2: Load and Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9g2aKYa9kG1Q"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "# we need to normalize the pixel values which range from 0 to 255 to 0 to 1\n",
    "x_train = x_train.astype(np.float32) / 255.0\n",
    "x_test = x_test.astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "colab_type": "code",
    "id": "UFEwYL2HJ5no",
    "outputId": "33287f7b-67bb-41f8-f5fd-9269d814d150"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "# creating a 5 X 5 grid for each image\n",
    "# we will be showing 25 images from the training set\n",
    "# binary because they are greyscale images so no colour channel, just black/white images\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_train[i], cmap = plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_B6mV5YZw_p7"
   },
   "source": [
    "## Task 3: Create Batches of Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oqwFFyrFkG7b"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "# shuffle the example with a size of 1000. the datset fills this buffer with 1000 elements, then\n",
    "# randomly samples from this buffer, then replaces the selected elements with new elements\n",
    "# This dataset fills a buffer with buffer_size elements, \n",
    "#then randomly samples elements from this buffer, replacing the selected elements with new elements.\n",
    "dataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(1000)\n",
    "# pre-fetch elements from the dataset with buffer size = 1\n",
    "# drop_remaider = True so that tensorflow ignores the last batch to get a full shape propagation\n",
    "#Combines consecutive elements of this dataset into batches.\n",
    "dataset = dataset.batch(batch_size, drop_remainder = True).prefetch(1)\n",
    "#Creates a Dataset that prefetches elements from this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w5qOeWQDxp7A"
   },
   "source": [
    "## Task 4: Build the Generator Network for DCGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e4qXzYgEs4RR"
   },
   "source": [
    "![GAN](DCGAN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generator** is an upsampling network with fractionally-strided convolutions\n",
    "\n",
    "**Discriminator** is a convolutional network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecture guidelines for stable Deep Convolutional GANs:\n",
    "\n",
    "(The points of difference between GANS and DCGANS):\n",
    "\n",
    "- Replace any pooling layers with strided convolutions (discriminator) and fractional-strided convolutions (generator).\n",
    "- Use batchnorm in both the generator and the discriminator.\n",
    "- Remove fully connected hidden layers for deeper architectures.\n",
    "- Use ReLU(or SELU) activation in generator for all layers expect for the output, which uses Tanh.\n",
    "- Use LeakyReLU activation in the discriminator for all layers(except for output layer where we will be using sigmoid activation function to perform binary classfication).\n",
    "\n",
    "[Source](https://arxiv.org/pdf/1511.06434.pdf): Radford et al, \"*Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks*\", ICLR 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E_Pz36D9T3dp"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "PMihRHcHT3hU",
    "outputId": "d16ceab2-d819-43ba-e359-3f895be61e61"
   },
   "source": [
    "We wanted to sample from complex, high dimensional distribution to generate the synthetic images but there is no direct way of doing that. So we will be making a transformation from the random Guassian noise distribution to the training images. We want the model to learn a transformation from this simple distribtuion(Guassian noise) to the training distribution(set)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discrimator is just like a binary CNN image classifier which tries to identify whether an image is real or fake."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be done using a two player game theoretic formulation using where te 2 players are the generator and the discrimator networks, they are going to be trained jointly using a mini-max game theoretic formulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to perform gradient descent on both the generator and discrimator where the objective function of the generator will be to try to prove the discriminator wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Execute only 1 of the below 2 cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LNoA-K62kHEI"
   },
   "outputs": [],
   "source": [
    "# we can set any value for no. of features ranging from 30 to much higher depeding on compute\n",
    "# power etc\n",
    "# we are going to upsample from the seed(random noise) until we get to the image size\n",
    "num_features = 100\n",
    "# input shape is the no of features\n",
    "generator = keras.models.Sequential([\n",
    "    keras.layers.Dense(7 * 7 * 128, input_shape = [num_features]),\n",
    "    keras.layers.Reshape([7, 7, 128]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2DTranspose(64, (5,5), (2,2), padding = 'same', activation = 'selu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2DTranspose(1, (5,5), (2,2), padding = 'same', activation = 'tanh')\n",
    "])\n",
    "# we can also start with 7 * 7 * 256 instead of 128 to improve performance\n",
    "# keras.layers.Dense(7 * 7 * 256, input_shape = [num_features]),\n",
    "# keras.layers.Reshape([7, 7, 256]),\n",
    "# then we can duplicate the conv2D layer and instead of having 64, we can have 128\n",
    "# keras.layers.Conv2DTranspose(128, (5,5), (1,1), padding = 'same', activation = 'selu'),\n",
    "# keras.layers.BatchNormalization(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Something like this:\n",
    "num_features = 100\n",
    "# input shape is the no of features\n",
    "generator = keras.models.Sequential([\n",
    "    keras.layers.Dense(7 * 7 * 256, input_shape = [num_features]),\n",
    "    keras.layers.Reshape([7, 7, 256]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2DTranspose(128, (5,5), (1,1), padding = 'same', activation = 'selu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2DTranspose(64, (5,5), (2,2), padding = 'same', activation = 'selu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2DTranspose(1, (5,5), (2,2), padding = 'same', activation = 'tanh')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "z8NRrD1WUYeb",
    "outputId": "44242809-8ece-4485-95d0-e37cc55da83a"
   },
   "outputs": [],
   "source": [
    "# seed or a vector of random noise we are going to pass to the generator to see the o/p without\n",
    "# the network being trained\n",
    "noise = tf.random.normal(shape = [1, num_features])\n",
    "generated_image = generator(noise, training = False)\n",
    "plot_utils.show(generated_image, 1)\n",
    "# this will show image of random noise, once the generator model has been trained, it will show\n",
    "# images from the training_set(by transforming this random noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rMUiBeXhVMWf"
   },
   "source": [
    "## Task 5: Build the Discriminator Network for DCGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute only 1 of the below 2 cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DOpPAq_ckHHz"
   },
   "outputs": [],
   "source": [
    "discriminator = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(64, (5,5), (2,2), padding = 'same', input_shape = [28, 28, 1]),\n",
    "    keras.layers.LeakyReLU(0.2),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Conv2D(128, (5,5), (2,2), padding = 'same'),\n",
    "    keras.layers.LeakyReLU(0.2),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "# we can repeat these layers, change 128 to 256 in this layer, stride to 1\n",
    "# keras.layers.Conv2D(256, (5,5), (1,1), padding = 'same'),\n",
    "# keras.layers.LeakyReLU(0.2),\n",
    "# keras.layers.Dropout(0.3),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# something like this\n",
    "discriminator = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(64, (5,5), (2,2), padding = 'same', input_shape = [28, 28, 1]),\n",
    "    keras.layers.LeakyReLU(0.2),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Conv2D(128, (5,5), (2,2), padding = 'same'),\n",
    "    keras.layers.LeakyReLU(0.2),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Conv2D(256, (5,5), (1,1), padding = 'same'),\n",
    "    keras.layers.LeakyReLU(0.2),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(1, activation = 'sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision will be a no b/w 0 and 1, if it is < 0.5, it means fake image, else real image\n",
    "decision = discriminator(generated_image)\n",
    "print(decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gjkSFNGGVT4I"
   },
   "source": [
    "## Task 6: Compile the Deep Convolutional Generative Adversarial Network (DCGAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop')\n",
    "discriminator.trainable = False\n",
    "gan = keras.models.Sequential([generator, discriminator])\n",
    "gan.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nKJzwn3ExORM"
   },
   "source": [
    "## Task 7: Define Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ic76LI4xfGPD"
   },
   "outputs": [],
   "source": [
    "# this creates the seed image\n",
    "seed = tf.random.normal(shape = [batch_size, num_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RX-t-8XmlemS"
   },
   "outputs": [],
   "source": [
    "def train_dcgan(gan, dataset, batch_size, num_features, epochs = 5):\n",
    "    generator, discriminator = gan.layers\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        print(\"Epoch {}/{}\".format(epoch + 1, epochs))\n",
    "        for X_batch in dataset:\n",
    "            noise = tf.random.normal(shape = [batch_size, num_features])\n",
    "            generated_images = generator(noise)\n",
    "            # concatenate list of generated images with the list of real images\n",
    "            X_fake_and_real = tf.concat([generated_images, X_batch], axis = 0)\n",
    "            # labels for fake image = 0, for real mages = 1\n",
    "            y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n",
    "            discriminator.trainable = True\n",
    "            discriminator.train_on_batch(X_fake_and_real, y1)\n",
    "            y2 = tf.constant([[1.]] * batch_size)\n",
    "            discriminator.trainable = False\n",
    "            gan.train_on_batch(noise, y2)\n",
    "        display.clear_output(wait = True)\n",
    "        generate_and_save_images(generator, epoch + 1, seed)\n",
    "    \n",
    "    display.clear_output(wait = True)\n",
    "    generate_and_save_images(generator, epochs, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NDbSHgN5gVT0"
   },
   "outputs": [],
   "source": [
    "## Source https://www.tensorflow.org/tutorials/generative/dcgan#create_a_gif\n",
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    predictions = model(test_input, training=False)\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    \n",
    "    for i in range(25):\n",
    "        plt.subplot(5, 5, i+1)\n",
    "        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='binary')\n",
    "        plt.axis('off')\n",
    "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ehb_zChMyMms"
   },
   "source": [
    "## Task 8: Train DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WIttFRtEkHKA"
   },
   "outputs": [],
   "source": [
    "x_train_dcgan = x_train.reshape(-1, 28, 28, 1) * 2. - 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EK6oZ_3ekHNP"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataset = tf.data.Dataset.from_tensor_slices(x_train_dcgan).shuffle(1000)\n",
    "dataset = dataset.batch(batch_size, drop_remainder = True).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "colab_type": "code",
    "id": "r8VXDKHikHO0",
    "outputId": "e3d078a3-833e-4c8c-b303-9fa9c3e2254b"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train_dcgan(gan, dataset, batch_size, num_features, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gToylYoE6Rw4"
   },
   "source": [
    "## Task 9: Generate Synthetic Images with DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "colab_type": "code",
    "id": "Lbr9e1gvkHVW",
    "outputId": "e9b4269b-5a85-406f-d2d2-d71c95917a57"
   },
   "outputs": [],
   "source": [
    "noise = tf.random.normal(shape = [batch_size, num_features])\n",
    "generated_images = generator(noise)\n",
    "plot_utils.show(generated_images, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MLy2L7uYlA_1"
   },
   "outputs": [],
   "source": [
    "## Source: https://www.tensorflow.org/tutorials/generative/dcgan#create_a_gif\n",
    "\n",
    "import imageio\n",
    "import glob\n",
    "\n",
    "anim_file = 'dcgan.gif'\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "    filenames = glob.glob('image*.png')\n",
    "    filenames = sorted(filenames)\n",
    "    last = -1\n",
    "    for i,filename in enumerate(filenames):\n",
    "        frame = 2*(i**0.5)\n",
    "        if round(frame) > round(last):\n",
    "            last = frame\n",
    "        else:\n",
    "            continue\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)\n",
    "\n",
    "import IPython\n",
    "display.Image(filename=anim_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make this model better by training it with larger no of epochs, say 50 or 100\n",
    "we can also make it better by increasing the no of layers in both the generator and discriminator"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DCGAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
